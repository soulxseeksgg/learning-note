
for kubernetes

เข้าเว็บ artifacthub 
    กดที่ link โหลด chart ของ logstash มา 
    ลบไฟล์ทิ้งให้เหลือแค่ template กับไฟล์ chart.yaml กับ value.yaml

flow
การติดตั้ง
elasticsearch
logstash
filebeat
kibana


1.container log
  ^ 
2. filebeat เข้าไปอ่าน
  
3. logstash เข้าไปรับผ่าน log จาก filebeat ผ่าน input
  
4. elasticsearch ถูกส่ง data มาให้จาก logstash ที่แปะผ่าน output

5. kibana มาอ่านใน elasticseach

เช็ค port แต่ละตัวว่าตรงไหม
ดู log แต่ละตัวว่าขึ้นไหม k logs pod ดู

คำสั่ง run : 
  helm install logstash . --namespace elk
  helm install filebeat . --namespace elk
  helm upgrade elasticsearch . --namespace elk
      k port-forward svc/elasticsearch-master -n elk 9200:9200
      curl http://localhost:9200/_cluster/health?pretty

  helm install kibana . --namespace elk  --no-hooks

  kubectl get configmap -n elk
  kubectl delete configmap kibana-kibana-helm-scripts -n elk

  bitnamic
  helm repo add bitnami https://charts.bitnami.com/bitnami
  helm show values bitnami/elasticsearch > values.yaml


  elasticsearch ram 879.4MB / 1GB, cpu 100m



--------------------------------------------------------------------------------------------------------------
1.#filebeats   //Fluent Bit (ฟลูอิ้นท์ บิท)
  filebeatConfig:
    filebeat.yml: |
      filebeat.inputs:
      - type: container
        paths:
          - /var/log/containers/*.log
        processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"

    output.logstash: //<---- เพิ่มส่วนนี้ เพื่อให้มัน filter log ก่อนใน logstash แล้วค่อยเอาไปเก็บใน elasticsearch หลังประมวลผล
        hosts: ["logstash-logstash:5044"]   //<<------ ไส่เป็นชื่อ service ใน k8s ของ logstash  


    ##################### ไม่ต้องไส่ก็ได้ ########################
    //เพิ่มพิเศษ
      แบบเลือก ราย container
          processors:
            - add_kubernetes_metadata:
                host: ${NODE_NAME}
                matchers:
                  - logs_path:
                      logs_path: "/var/log/containers/"
            - drop_event:
                when:
                  not:
                    or:
                      - contains:
                          kubernetes.container.name: "postgres"
                      - contains:
                          kubernetes.container.name: "redis"
                      - contains:
                          kubernetes.container.name: "kafka"

--------------------------------------------------------------------------------------------------------------

2.#logstash
1.1 เพิ่ม input output ในเส้นทางการเก็บของ logstash
  ไปที่ tag logstashPipeline set input และ output
  logstashPipeline:
    logstash.conf: |      //<<<------ รับ input เป็น filebeat port 5044
      input {
        beats {
          port => 5044
        }
      }
      output {
        elasticsearch {
        hosts => "http://elasticsearch-master:9200"    //<<<------ ต่อ host elasticsearch เพื่อเก็บ ไส่เป็นชื่อ service ของ pod
        } 
      }   

1.2 เชื่อมต่อไปยัง port ของ filebeat และ kibana ข้างบนแค่อ้างถึงไม่ใช่การ config เพื่อ connect จริงๆ
service:
  annotations: {}
  type: ClusterIP
  loadBalancerIP: ""
  ports:
    - name: beats
      port: 5044
      protocol: TCP
      targetPort: 5044
    - name: http   //<---- เอาไว้ให้มันเข้า logstash ได้ผ่าน api เอาไว้ตรวจสอบ health ต่างๆ ถ้าไม่ใช้ api ก็ลบก็ได้
      port: 8080
      protocol: TCP
      targetPort: 8080     
--------------------------------------------------------------------------------------------------------------


3.#elasticsearch   
  //ไม่ต้องไส่อะไร รอรับอย่างเดียว รอรับและรอดึงเหมือนกับก้อน database postgres สีม่วงๆ อยู่นิ่งๆรอคนอื่นมา insert ลงและมา query ใช้

curl -X GET localhost:8080/_cat   //-X คืออ้าง method defult เป็น GET ถ้าไม่ส่ใช้ POST ไม่ได้
--------------------------------------------------------------------------------------------------------------



4.#kibana
1. ชี้ไปที่ service ของ elasticsearch
  elasticsearchHosts: "https://elasticsearch-master:9200"  //<<----ชี้ไปที่ database ของเรา elasticsearch-master มันเป็นเชื่อของ service ใน k8s ของ elasticsearch

2. ตั้งค่าให้เข้าได้จากเว็บข้างนอก
   //ต้องลง ingress-nginx ก่อนด้วยถ้ายังไม่เคยมี มันไม่ auto โหลดให้นะ
ingress:
  enabled: true
  className: "nginx"
  pathtype: ImplementationSpecific
  annotations:
   kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  hosts:
    - host: kubernetes-docker.internal
      paths:
        - path: /

    
  ##ติดตั้ง ingress-nginx กรณ๊ยังไม่มี
  helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
  helm repo update
  helm install nginx-ingress ingress-nginx/ingress-nginx -n ingress-nginx --create-namespace

--------------------------------------------------------------------------------------------------------------
#login

k port-forward service/kibana 8090:5061 -n elk

login
  ไปเอา secret ของ elasticsearch มาใน -n elk
  k get secret -n elk 
  จะเจอ secret ของ elk

  k get secret/elasticsearch-master-credentials -n elk -o yaml

  password: aEJ4WklkaG15bkYxY0Vvdw==
  username: ZWxhc3RpYw==

  echo -n "aEJ4WklkaG15bkYxY0Vvdw==" | base64 --decode


