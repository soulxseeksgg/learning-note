
-------อธิบายโครงสร้าง yaml logstash -----
1.# deployment
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: logstash
    namespace: elk
    labels:
      app: logstash
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: logstash
    template:
      metadata:
        labels:
          app: logstash
      spec:
        containers:
          - name: logstash
            image: docker.elastic.co/logstash/logstash:7.2.0
            resources:
              limits:
                cpu: 1200m <<---- cpu 1200mm ไม่งั้นไม่ขึ้น ไม่เร็ว ต้องระดับ 1Gb+
                memory: 1Gi
            ports:
              - containerPort: 5044
                name: beats-input

            volumeMounts:
              - name: logstash-config-reload
                mountPath: /usr/share/logstash/config/logstash.yml  <<----ไฟล์ config ของ logstash เลย กำหนดพวก log level, reload ต่างๆในไฟล์นี้
                subPath: logstash.yml

              - name: logstash-pipelines
                mountPath: /usr/share/logstash/config/pipelines.yml <<--- เอาไว้กำหนด id ของ pipeline มี 3 ตัวก็ 3 อันต้อง config ไว้ในนี้
                subPath: pipelines.yml

              - name: logstash-main-input
                mountPath: /usr/share/logstash/pipeline/main-input.conf <<--- ทำ pipeline ซ้อน pipeline ทำให้มันรับจาก port เดียวกันได้ และค่อยส่งไปยัง pipeline อื่น
                subPath: main-input.conf

              - name: logstash-myapp-pipeline
                mountPath: /usr/share/logstash/pipeline/myapp-pipeline.conf <<--- pipeline แยก อันที่ 1
                subPath: myapp-pipeline.conf

              - name: logstash-redis-pipeline
                mountPath: /usr/share/logstash/pipeline/redis-pipeline.conf <<--- pipeline แยก อันที่ 1
                subPath: redis-pipeline.conf

              - name: logstash-pattern
                mountPath: /usr/share/logstash/pattern/mypattern.patterns <<--- เอาไว้สร้าง pattern ของตัวเอง การเรียกใช้อยู่ข้างล่าง
                subPath: mypattern.patterns  

              - name: logstash-data
                mountPath: /usr/share/logstash/data/   <<---- เอาไว้เก็บ data ที่มันโหลดมา ถึงกับต้องทำ pv ให้มันเลย

        volumes:
          - name: logstash-config-reload  <<----- map กับชื่อข้างบน
            configMap:
              name: logstash-configmap  <<----- map ชี้ไปที่ไฟล์ configmap ข้างล่าง

          - name: logstash-pipelines <<----- เหมือนกัน
            configMap:    <---- ตรงนี้บอกว่าใช้ map แบบ configmap
              name: logstash-configmap <<----- เหมือนกันห   

          - name: logstash-main-input
            configMap:
              name: logstash-configmap
                  
          - name: logstash-myapp-pipeline
            configMap:
              name: logstash-configmap

          - name: logstash-redis-pipeline
            configMap:
              name: logstash-configmap      

          - name: logstash-pattern
            configMap:
              name: logstash-configmap

          - name: logstash-data
            persistentVolumeClaim:
              claimName: logstash-pvc   <<--- ชี้ path หรือตัวแปร volume นี้หรือข้างบนไปที่ pvc ที่สร้างไว้ ว่าให้มันใช้เคลมตัวนี้และเคลมมันจะไปหาจับ pv เอง ซึ่งเราก็สร้างให้มันพอดีไว้แล้ว 

---
2. # PV สร้างไว้สำหรับเก็บข้อมูลแบบ HD ไปแบ่งเอามาจาก HD
  apiVersion: v1
  kind: PersistentVolume
  metadata:
    name: logstash-pv
  spec:
    capacity:
      storage: 1Gi   <<---แบ่งมาจาก hostpath 1Gb
    volumeMode: Filesystem
    accessModes:
      - ReadWriteOnce
    persistentVolumeReclaimPolicy: Retain  <<--- Retain คือคงทนถาวร แม้ pvc จะถูกลบ แต่ตัวนี้ก็จะไม่หาย
    storageClassName: hostpath <<--- ชื่อ hd ของ kubernetes
    hostPath:
      path: /usr/share/logstash/data/ <<--- path ที่จะให้สร้าง ซึ่งเราเอาให้เหมือนกับ path จริงเลยจะได้ไม่สับสน

---
3. # PVC ตัวผูกกับ pv ซึ่งเหมือนกับการไปขอเสียบ เรากำหนดไว้ว่าอยากได้ 1Gb ใน hostpath นี้มันก็จะไปหา pvc ให้เองเลยที่มันพอดีกับความจุ ไม่ต้องอ้างชื่อตรงๆ
  apiVersion: v1
  kind: PersistentVolumeClaim
  metadata:
    name: logstash-pvc
    namespace: elk 
  spec:
    accessModes:
      - ReadWriteOnce
    resources:
      requests:
        storage: 1Gi  <<--- ต้องการ 1Gb
    storageClassName: hostpath   <---- ที่ในตรงนี้

4 # config map ตัวเดือด
  apiVersion: v1
  kind: ConfigMap     <<--- kind ประเภท configmap
  metadata:
    name: logstash-configmap   <<--- ชื่อ configmap
    namespace: elk   <<--- namespace ที่จะอยู่
  data:
    
    logstash.yml: |           <<------ configmap ไฟล์แรก
      config.reload.automatic: true
      config.reload.interval: 3s     <<----- เอาไว้สั่งให้มัน reload ซึ่งมันทำไม่ไม่ได้หรอกบน k8s ไม่รู้ทำยังไง มันเป็น configmap มันไม่ใช่ไฟล์ไอ้ตัว pipeline อ่ะ มันไม่ให้แก้ สิทธ์ไฟล์ configmap piple มันเป็น root
    
    pipelines.yml: |          <<------ configmap ไฟล์ที่สอง
      - pipeline.id: main-input
        path.config: "/usr/share/logstash/pipeline/main-input.conf"

      - pipeline.id: myapp-pipeline
        path.config: "/usr/share/logstash/pipeline/myapp-pipeline.conf"

      - pipeline.id: redis-pipeline
        path.config: "/usr/share/logstash/pipeline/redis-pipeline.conf"
    

    main-input.conf: |
      input {    <<----- ทำ input กลาง รับจาก port ของ filebeat
        beats {
          port => 5044
          type => "beats"
        }
      }

      output {
        if [appname][app] == "myapp" {    <<---เช็คเงื่อนไขและส่งไปยัง pipline อื่น
          pipeline { send_to => "myapp-pipeline" }  <<---- ในทีนี้มี 2 ตัว
        } else if [appname][app] == "redis" {
          pipeline { send_to => "redis-pipeline" }  <<--- ของ redis
        }
      }

    myapp-pipeline.conf: |    <---- pipeline ของ myapp
      input {
        pipeline {
          address => "myapp-pipeline"   <<--- รับ input แบบ pipeline to pipeline
        }
      }

      filter {
      
        grok {  // grok มันตัดไส่ตัวแปรไว้ ถ้าไส่มากกว่า 1 ตัวแปร มันต้องไส่ข้างหลังให้ครบ ให้เหมือน formate จริง
            match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{DATA:log_level} %{NUMBER:pid} --- \[%{DATA:thread}\] %{DATA:class} : %{GREEDYDATA:messages}" }
        }

        date {
          match => ["timestamp", "ISO8601"]  <<---- แปลงไอ้ข้างที่ตัดมาจาก grok แปลงด้วย formate ที่ kibana ชื่นชอบ มันคือการแปลง string เป็น timestamp เฉยๆ
          target => "event_timestamp"    <<--- เก็บไว้ในตัวแปรอะไร ถ้าไม่ไส่ มันจะทับไปใน @timestamp เลย
        }

        if "_grokparsefailure" in [tags] {  <<---- ถ้า grok มันตัดไม่ได้ มันจะตกเคสนี้ เราก็เพิ่ม fields ให้มัน แล้วเอาไปเช็คข้างล่างว่าให้ส่งแยก ตัวที่เฟล
          mutate {
            add_field => { "parse_status" => "failed" }
          }
        }

        mutate {
          gsub => [ 
            "messages", "^\s+|\s+$", ""  <<---- replcae ช่องว่างหน้าหลัง มันไม่มี trim ให้ใช้หรอวะ
            ,"log_level", "^\s+|\s+$", ""
            ,"class", "^\s+|\s+$", ""
          ]
          
          remove_field => ["agent","ecs","@version","tags","timestamp","pid","message"]  <<---- ลบฟิลด์ที่เกะกะออก
        }

      }

      output {

          stdout { codec => rubydebug }  <<--- สามารถส่งออกได้หลายทาง

          if [parse_status] == "failed" {
            elasticsearch {
              hosts => ["http://elasticsearch:9200"]
              index => "log-failed-%{[appname][app]}-%{+yyyyMMdd}"  <<--- แยกพร้อมทั้งกำหนด index
            }
          } else {
            elasticsearch {
              hosts => ["http://elasticsearch:9200"]
              index => "log-%{[appname][app]}-%{+yyyyMMdd}"
            }
          }
        
      }

    redis-pipeline.conf: |  <<<----- pipeline ตัวที่ 2
      input {
        pipeline {
          address => "redis-pipeline"
        }
      }

      filter {
        grok {
            patterns_dir => ["/usr/share/logstash/pattern/"]  <<----อ้างอิง pattern ของเราที่สร้างเอง (ข้างล่าง)

            match => { "message" => "%{REDIS_MESSAGE_TIME:timestamp} %{REDIS_LOG_SYMBOL:log_symbol} %{GREEDYDATA:messages}" }
        }

        date {
          match => ["timestamp", "ISO8601"]
          target => "event_timestamp"
        }

        if "_grokparsefailure" in [tags] {
          mutate {
            add_field => { "parse_status" => "failed" }
          }
        }

        mutate {
          gsub => [ 
            "messages", "^\s+|\s+$", ""
            ,"log_symbol", "\s+", "" 
          ]
    
          remove_field => ["agent","ecs","@version","tags","stream","host","timestamp","message"]
        }

        translate {   <<---- map ตัวแปรได้ด้วย
          field => "log_symbol"  <--- ชื่อที่จะเช็ค
          destination => "log_level"  <--- ชื่อใหม่
          dictionary => {
            "#" => "WARNING"
            "*" => "INFO"
            "-" => "DEBUG"
            "+" => "TRACE"
          }
        }

      }

      output {

          stdout{}

          if [parse_status] == "failed" {
            elasticsearch {
              hosts => ["http://elasticsearch:9200"]
              index => "log-failed-%{[appname][app]}-%{+yyyyMMdd}"
            }
          } else {
            elasticsearch {
              hosts => ["http://elasticsearch:9200"]
              index => "log-%{[appname][app]}-%{+yyyyMMdd}"
            }
          }
        
      }

    mypattern.patterns: |
      REDIS_MESSAGE_TIME %{MONTHDAY} %{MONTH} %{YEAR} %{TIME}
      REDIS_LOG_SYMBOL [\#\*\-\+]

---

5. #service กำหนดการเข้าถึงต่างๆเช่นแบบ nodeport หรือว่า clusterIp ซึ่งต้อง port forward เอาเมื่อจะใช้
  apiVersion: v1
  kind: Service
  metadata:
    name: logstash
    namespace: elk
    labels:
      app: logstash
  spec:
    selector:
      app: logstash
    ports:
    - protocol: TCP
      port: 5044
      targetPort: 5044
    type: ClusterIP  


-------อธิบายโครงสร้าง yaml logstash -----



--note--
  grok มาจากคำว่า "grokking" ซึ่งหมายถึงการเข้าใจบางสิ่งอย่างลึกซึ้งและชัดเจน 
  GeoIP (จีโอ ip) "geo" มาจากภาษากรีก ซึ่งหมายถึง "โลก" หรือ "พื้นดิน" เก็บ ip รอบพื้นโลก

  # kv จับคู่แบบ key value
    ตัวอย่าง log
      time=2025-02-13T04:20:18.527Z level=INFO user_id=123 action

      filter {
        grok {}
        kv {   //ไม่ได้อยู่ใน grok แต่ให้ grok ตัดตัวแปรส่งไปให้ได้
          source => "message"
          field_split => " "  #กลั้นคำด้วยช่องว่าง
          value_split => "="  #ดึง key value ด้วย =
          trim => "[]\""      # ตัด [ ] และ " ออกจากค่า

          prefix => "log_"   # ตั้งชื่อ field เองได้
          exclude_keys => ["debug", "session_id"] #ไม่เอาบางคอลัมป์
        }
      }

    output จะได้
      {
        "time": "2025-02-13T04:20:18.527Z",
        "level": "INFO",
        "user_id": "123"  #อันที่ไม่ match จะไม่ถูกเก็บลงใน key และ logstash จะไม่หยุดทำงาน
      }


 ----คำสั่ง-----
kdd logstash -n elk //มันต้องลบก่อนเพราะกินแรมจัด ขึ้นพร้อมกันไม่ได้แรมไม่พอ ต้องลบออก่อน 
k apply -f logstash.yaml //แล้วลงใหม่หมด
kl app=logstash -n elk     